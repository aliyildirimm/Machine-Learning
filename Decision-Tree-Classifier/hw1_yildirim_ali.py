# -*- coding: utf-8 -*-
"""hw1-yildirim-ali.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YHCuLL4FaPq0GMtuz-cJylXiM_1eKjqo

CS412 - Machine Learning - 2020

Goal

Build a decision tree classifier with the scikit library function calls to classify digits in the MNIST dataset.

**1) Initialize**


**2) Load training dataset**

Read from Keras library.
"""

# Load the Pandas libraries with alias 'pd' 
import numpy as np
import pandas as pd
import keras
from keras.datasets import mnist

(X_train_prev, y_train_prev), (X_test, y_test) = mnist.load_data()

"""**3) Understanding the dataset**"""

print('Data Dimensionality: ', X_train_prev.shape)

train_dataframe = pd.DataFrame(X_train_prev.reshape(60000, 28*28))
train_dataframe['label'] = y_train_prev
train_dataframe.columns

# print first 5 rows in your dataset
print('Head of Data: ')
train_dataframe.head()

"""**4) Shuffle and Split TRAINING data as train (also called development) (80%) and validation (20%)**"""

from sklearn.utils import shuffle

# Shuffle the training data
train_df_shuffled = shuffle(train_dataframe, random_state=42)
X_shuffled = train_df_shuffled.drop("label", axis = 1)
y_shuffled = train_df_shuffled["label"]

#X_shuffled.shape, y_shuffled.shape

# Split 80-20
from sklearn.model_selection import train_test_split
X_train, X_valid, y_train, y_valid = train_test_split(X_shuffled, y_shuffled, test_size=0.2)
X_train.shape, X_valid.shape

"""**5) Train a decision tree classifier on development/train data and do model selection using the validation data.**

*   Train 3 decision tree classifiers with different values of "min_samples_split" which is the minimum number of samples required to split an internal node: min_samples_split = [default = 2, 5, 10].

*   Test the 3 models on validation set and choose the best one.

*   Plot the train and validation set errors for those 3 settings - on one plot.

"""

# Train decision tree classifiers
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics 
min_samples_split = [ 2, 5, 10]

# Evaluate on validation set
acc_list = []
acc_train_list = []
err_list = [] 
err_train_list = []
for i in range(0,3):
  clf = DecisionTreeClassifier(min_samples_split = min_samples_split[i])
  clf.fit(X_train, y_train)

  y_pred_valid = clf.predict(X_valid)
  value_valid = metrics.accuracy_score(y_valid, y_pred_valid)
  acc_list.append(value_valid)
  err_list.append(1-value_valid)

  y_pred_train = clf.predict(X_train)
  value_train = metrics.accuracy_score(y_train, y_pred_train)
  acc_train_list.append(value_train)
  err_train_list.append(1-value_train)

  print("When min_samples_split is:", min_samples_split[i], ", accuracy score is:", value_valid)

# Plot error:
import matplotlib.pyplot as plt
x_axis = ['model1', 'model2', 'model3']
plt.scatter(x_axis, acc_list)
plt.scatter(x_axis, acc_train_list)
plt.plot(x_axis, acc_list, label = "Validation acc")
plt.plot(x_axis, acc_train_list, label = "Train acc")
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""**6) Test your CHOSEN classifier on Test set**
*   Load test data
*   Apply same pre-processing as training data (probably none)
*   Predict the labels of testing data using the best chosen SINGLE model out of the models that you have tried from step 6 (you have selected your model according to your validation results) and report the accuracy.
"""

# test prediction using a decision tree with all default parameters and ..... min-split value 
import operator
index, value = max(enumerate(acc_list), key=operator.itemgetter(1))

clf_2 = DecisionTreeClassifier(min_samples_split = min_samples_split[index])
clf_2.fit(X_train, y_train)
y_pred_2 = clf_2.predict(X_test.reshape(10000, 28*28))

# Report your accuracy
value = metrics.accuracy_score(y_test, y_pred_2)
print("Accuracy score is:", value)

"""**7) Notebook & Report**

The problem was classification of MNIST data set using a decision tree classifier. Firstly, data was imported by using Keras. It has 10000 test examples and 60000 train examples inside of it. After data imported from Keras, training data was shuflled, then train data was splitted as train and validation sets by using train_test_split method. In addition, since our datas were 28x28 matrices, each data was reshaped to flattened to use pandas library. As a result, instead of 28x28 matrix datas, arrays of size (28*28=784) 784 was used.  Validation set ratio was 20% whereas train set ratio was 80%. Training set was fit the model, then model has tested on validation set. In order to choose best model in terms of accuracy and overfitting issues hyperparameter tuning was done. 3 different decision trees obtained through changing 'min_samples_split' feature of the model. These values were 2, 5 and 10. In order to prevent from overfitting also accuracy scores of training sets were observed. Eventually, 3rd tree which has min_samples_split = 10 was the best model. The reason was that it got best accuracy score on validation set.  But it can change from run to run. As I learned from the course, increasing min_sample_split results in decrease of overfitting probabilty, and it actually seems to decreased overfitting by looking at training accuracy score.

Obtained training accuracies were almost 100%, 98%, and 96% whereas validation accuracies were 86.78%, 86.85%, and 86.9%. After this point, model was tested on test data set with the model which got the highest validation accuracy. Obtained accuracy on test set was 86.79% which is close to validation set accuracy of 3rd model.
"""